{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# from scipy.misc import imread, imresize (depreciated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Obtaining dependency information for imageio from https://files.pythonhosted.org/packages/c0/69/3aaa69cb0748e33e644fda114c9abd3186ce369edd4fca11107e9f39c6a7/imageio-2.33.1-py3-none-any.whl.metadata\n",
      "  Downloading imageio-2.33.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\chang.laptop-klp71l1n\\anaconda3\\lib\\site-packages (from imageio) (1.24.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\chang.laptop-klp71l1n\\anaconda3\\lib\\site-packages (from imageio) (9.4.0)\n",
      "Using cached imageio-2.33.1-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.33.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\Chang.LAPTOP-KLP71L1N\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Import the sys module, which provides access to some variables used or maintained by the Python interpreter\n",
    "import sys\n",
    "\n",
    "# Install the imageio package using pip\n",
    "# The '!{sys.executable}' part ensures that pip installs the package in the same Python environment as the current Jupyter kernel\n",
    "!{sys.executable} -m pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # Read the image using imageio\n",
    "    img = imageio.imread(image)\n",
    "\n",
    "    # Resize the image using PIL\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize((256, 256)) #256x256x3\n",
    "\n",
    "    # Convert the image to a numpy array and transpose to make channels first\n",
    "    img = np.array(img).transpose(2, 0, 1)\n",
    "\n",
    "    # Normalize pixel values to [0, 1]\n",
    "    img = img / 255.\n",
    "\n",
    "    # Convert the numpy array to a PyTorch tensor and move it to GPU\n",
    "    img = torch.FloatTensor(img).cpu()\n",
    "\n",
    "    # Define a normalization transform\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # Apply the normalization transform\n",
    "    img = normalize(img) # (3, 256, 256)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model:\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # First convolutional layer: 3 input channels, 6 output channels, 5x5 kernel, with default 0 padding and stride of 1\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)   \n",
    "        \n",
    "        # Max pooling layer with 2x2 kernel and stride 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)  \n",
    "        \n",
    "        # Second convolutional layer: 6 input channels, 12 output channels, 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(6, 12, 5)  \n",
    "        \n",
    "        # First fully connected layer: input size is 12*61*61, output size is 120\n",
    "        self.fc1 = nn.Linear(12 * 61 * 61, 120)\n",
    "        \n",
    "        # Second fully connected layer: input size is 120, output size is 10\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    # consider an image of size 256x256:\n",
    "    def forward(self, x):\n",
    "        # Forward pass of the input through the CNN:\n",
    "        \n",
    "        # output size = [ (256 - 5 + 2(0) ) / 1 ] + 1 --> 252x252:\n",
    "        x = F.relu(self.conv1(x))                # Apply first convolutional layer and ReLU\n",
    "        \n",
    "        # output_size = 252 / 2 --> 126x126:\n",
    "        x = self.pool(x)                         # Apply max pooling\n",
    "        \n",
    "        # output size = [ (126 - 5 + 2(0) ) / 1 ] + 1 --> 122x122:\n",
    "        x = F.relu(self.conv2(x))                # Apply second convolutional layer and ReLU\n",
    "        \n",
    "        # output size = 122/2 --> 61x61:\n",
    "        x = self.pool(x)                         # Apply max pooling\n",
    "        \n",
    "        # (1, 44652):\n",
    "        x = x.view(-1, 12 * 61 * 61)             # Flatten the output for the fully connected layer\n",
    "        \n",
    "        # (1, 120):\n",
    "        x = F.relu(self.fc1(x))                  # Apply first fully connected layer and ReLU\n",
    "        \n",
    "        # (1, 10):\n",
    "        x = self.fc2(x)                          # Apply second fully connected layer\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CNN model\n",
    "model = CNN()\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize the optimizer with Stochastic Gradient Descent (SGD)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chang.LAPTOP-KLP71L1N\\AppData\\Local\\Temp\\ipykernel_17340\\4175269825.py:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(image)\n"
     ]
    }
   ],
   "source": [
    "# Process the image using the defined function\n",
    "image = process_image('test.jpg')\n",
    "\n",
    "# Add a batch dimension to the image tensor\n",
    "image = image.unsqueeze(0)  # This changes the shape from [C, H, W] to [1, C, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# Feed the processed image through the model\n",
    "output = model(image)\n",
    "\n",
    "# Print the shape of the output\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([12])\n",
      "fc1.weight \t torch.Size([120, 44652])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([10, 120])\n",
      "fc2.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict:\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "\n",
    "for param_tensor in model.state_dict():\n",
    "    # Iterate through each parameter tensor in the state dictionary\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state dictionary to a file\n",
    "torch.save(model.state_dict(), 'model.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Saving Model State Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=44652, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following line if you need to create a new instance of the model:\n",
    "# model = CNN()\n",
    "\n",
    "# Load the saved state dictionary into the model\n",
    "model.load_state_dict(torch.load('model.pth.tar'))\n",
    "\n",
    "model.eval()     #set dropout and batch normalization layers to evaluation mode before inference (testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading a General Checkpoint for Inference and/or to Resuming Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the CNN model and move it to the CPU:\n",
    "model = CNN().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SGD optimizer:\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint dictionary:\n",
    "checkpoint = {\n",
    "    'epoch': 1,  # The current epoch number\n",
    "    'model_state_dict': model.state_dict(),  # The state dictionary of the model (weights, biases, etc.)\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # The state dictionary of the optimizer (momentum, learning rate, etc.)\n",
    "    'loss': 0.2  # The loss value at the time of saving\n",
    "}\n",
    "\n",
    "# Save the checkpoint to a file\n",
    "torch.save(checkpoint, 'model.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Checkpoint:\n",
    "checkpoint = torch.load('model.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model state into the model\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Load the saved optimizer state into the optimizer\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Retrieve the epoch number from the checkpoint\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "# Retrieve the loss value from the checkpoint\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=44652, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If testing\n",
    "model.eval()\n",
    "\n",
    "# If resuming training\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
